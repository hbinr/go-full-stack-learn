# Microservices test architecture. Can you sleep well without end-to-end tests?
å¾®æœåŠ¡æµ‹è¯•æž¶æž„ã€‚æ²¡æœ‰ç«¯åˆ°ç«¯çš„æµ‹è¯•ï¼Œä½ èƒ½ç¡å¾—å¥½å—ï¼Ÿ

ç¿»è¯‘è‡ª:[https://threedots.tech/post/microservices-test-architecture/)([ç¿»è¯‘è‡ª:](https://threedots.tech/post/microservices-test-architecture/))


Do you know the rare feeling when you develop a new application from scratch and can cover all lines with proper tests?

ä½ çŸ¥é“å½“ä½ ä»Žå¤´å¼€å§‹å¼€å‘ä¸€ä¸ªæ–°çš„åº”ç”¨ç¨‹åºï¼Œå¹¶èƒ½ç”¨é€‚å½“çš„æµ‹è¯•è¦†ç›–æ‰€æœ‰çš„çº¿è·¯æ—¶ï¼Œé‚£ç§ç½•è§çš„æ„Ÿè§‰å—ï¼Ÿ

I said â€œrareâ€ because most of the time, you will work with software with a long history, multiple contributors, and not so obvious testing approach. Even if the code uses good patterns, the test suite doesnâ€™t always follow.

æˆ‘è¯´ "ç½•è§ "æ˜¯å› ä¸ºåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ æ‰€å·¥ä½œçš„è½¯ä»¶æœ‰å¾ˆé•¿çš„åŽ†å²ï¼Œæœ‰å¤šä¸ªè´¡çŒ®è€…ï¼Œè€Œä¸”æµ‹è¯•æ–¹æ³•ä¸æ˜¯é‚£ä¹ˆæ˜Žæ˜¾ã€‚å³ä½¿ä»£ç ä½¿ç”¨äº†å¥½çš„æ¨¡å¼ï¼Œæµ‹è¯•å¥—ä»¶ä¹Ÿä¸ä¸€å®šèƒ½è·Ÿä¸Šã€‚

Some projects have no modern development environment set up, so there are only unit tests for things that are easy to test. For example, they test single functions separately because itâ€™s hard to test the public API. The team needs to manually verify all changes, probably on some kind of staging environment. You know what happens when someone introduces changes and doesnâ€™t know they need to test it manually.

æœ‰äº›é¡¹ç›®æ²¡æœ‰å»ºç«‹çŽ°ä»£çš„å¼€å‘çŽ¯å¢ƒï¼Œæ‰€ä»¥åªæœ‰ä¸€äº›å®¹æ˜“æµ‹è¯•çš„ä¸œè¥¿çš„å•å…ƒæµ‹è¯•ã€‚ä¾‹å¦‚ï¼Œä»–ä»¬å•ç‹¬æµ‹è¯•å•ä¸ªå‡½æ•°ï¼Œå› ä¸ºå¾ˆéš¾æµ‹è¯•å…¬å…±APIã€‚å›¢é˜Ÿéœ€è¦æ‰‹åŠ¨éªŒè¯æ‰€æœ‰çš„å˜åŒ–ï¼Œå¯èƒ½æ˜¯åœ¨æŸç§æš‚å­˜çŽ¯å¢ƒä¸Šã€‚ä½ çŸ¥é“å½“æœ‰äººå¼•å…¥å˜åŒ–è€Œä¸çŸ¥é“ä»–ä»¬éœ€è¦æ‰‹åŠ¨æµ‹è¯•æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚

Other projects have no tests from the beginning. It allows quicker development by taking shortcuts, for example, keeping dependencies in the global state. When the team realizes the lack of tests causes bugs and slows them down, they decide to add them. But now, itâ€™s impossible to do it reasonably. So the team writes an end-to-end test suite with proper infrastructure in place.

å…¶ä»–é¡¹ç›®ä»Žä¸€å¼€å§‹å°±æ²¡æœ‰æµ‹è¯•ã€‚å®ƒé€šè¿‡èµ°æ·å¾„ä½¿å¼€å‘é€Ÿåº¦åŠ å¿«ï¼Œä¾‹å¦‚ï¼Œå°†ä¾èµ–å…³ç³»ä¿æŒåœ¨å…¨å±€çŠ¶æ€ã€‚å½“å›¢é˜Ÿæ„è¯†åˆ°ç¼ºä¹æµ‹è¯•ä¼šå¯¼è‡´bugå¹¶å‡æ…¢ä»–ä»¬çš„é€Ÿåº¦æ—¶ï¼Œä»–ä»¬å†³å®šå¢žåŠ æµ‹è¯•ã€‚ä½†çŽ°åœ¨ï¼Œä¸å¯èƒ½åˆç†åœ°åšåˆ°è¿™ä¸€ç‚¹ã€‚å› æ­¤ï¼Œå›¢é˜Ÿå†™äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æµ‹è¯•å¥—ä»¶ï¼Œå¹¶å»ºç«‹äº†é€‚å½“çš„åŸºç¡€è®¾æ–½ã€‚

End-to-end tests might give you some confidence, but you donâ€™t want to maintain such a test suite. Itâ€™s hard to debug, takes a long time to test even the simplest change, and releasing the application takes hours. Introducing new tests is also not trivial in this scenario, so developers avoid it if they can.

ç«¯åˆ°ç«¯æµ‹è¯•å¯èƒ½ä¼šç»™ä½ ä¸€äº›ä¿¡å¿ƒï¼Œä½†ä½ å¹¶ä¸æƒ³ç»´æŠ¤è¿™æ ·çš„æµ‹è¯•å¥—ä»¶ã€‚å®ƒå¾ˆéš¾è°ƒè¯•ï¼Œå³ä½¿æ˜¯æœ€ç®€å•çš„å˜åŒ–ä¹Ÿè¦èŠ±å¾ˆé•¿æ—¶é—´æ¥æµ‹è¯•ï¼Œè€Œå‘å¸ƒåº”ç”¨ç¨‹åºéœ€è¦å‡ ä¸ªå°æ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¼•å…¥æ–°çš„æµ‹è¯•ä¹Ÿä¸æ˜¯å°äº‹ï¼Œå› æ­¤ï¼Œå¦‚æžœå¯ä»¥çš„è¯ï¼Œå¼€å‘äººå‘˜ä¼šé¿å…è¿™æ ·åšã€‚


I want to introduce some ideas that have worked for us so far and should help you avoid the scenarios above.

æˆ‘æƒ³ä»‹ç»ä¸€äº›åˆ°ç›®å‰ä¸ºæ­¢å¯¹æˆ‘ä»¬æœ‰æ•ˆçš„æƒ³æ³•ï¼Œåº”è¯¥å¯ä»¥å¸®åŠ©ä½ é¿å…ä¸Šè¿°æƒ…å†µçš„å‘ç”Ÿã€‚


This post is not about which testing library is best or what tricks you can use (although I will show a few tips). Itâ€™s closer to something I would call â€œtest architectureâ€. Itâ€™s not only about â€œhowâ€, but also â€œwhereâ€, â€œwhatâ€, and â€œwhyâ€.

è¿™ç¯‡æ–‡ç« ä¸æ˜¯å…³äºŽå“ªä¸ªæµ‹è¯•åº“æœ€å¥½ï¼Œæˆ–è€…ä½ å¯ä»¥ä½¿ç”¨ä»€ä¹ˆæŠ€å·§ï¼ˆå°½ç®¡æˆ‘å°†å±•ç¤ºä¸€äº›æŠ€å·§ï¼‰ã€‚å®ƒæ›´æŽ¥è¿‘äºŽæˆ‘ç§°ä¹‹ä¸º "æµ‹è¯•æž¶æž„"çš„ä¸œè¥¿ã€‚å®ƒä¸ä»…æ˜¯å…³äºŽ "å¦‚ä½•"ï¼Œè€Œä¸”è¿˜æœ‰ "å“ªé‡Œ"ã€"ä»€ä¹ˆ "å’Œ "ä¸ºä»€ä¹ˆ"ã€‚

Thereâ€™s been a lot of discussion on different types of tests, for example, the â€œtest pyramidâ€ (Robert mentioned it in this section about testing scenarios). Itâ€™s a helpful model to keep in mind. However, itâ€™s also abstract, and you canâ€™t easily measure it. I want to take a more practical approach and show how to introduce a few kinds of tests in a Go project.

å…³äºŽä¸åŒç±»åž‹çš„æµ‹è¯•æœ‰å¾ˆå¤šè®¨è®ºï¼Œä¾‹å¦‚ï¼Œ"[æµ‹è¯•é‡‘å­—å¡”](https://martinfowler.com/bliki/TestPyramid.html)"ï¼ˆç½—ä¼¯ç‰¹åœ¨å…³äºŽæµ‹è¯•åœºæ™¯çš„[è¿™ä¸€èŠ‚](https://threedots.tech/post/database-integration-testing/#2-testing-enough-scenarios-on-all-levels)ä¸­æåˆ°ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„æ¨¡åž‹ï¼Œè¦ç‰¢è®°åœ¨å¿ƒã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿæ˜¯æŠ½è±¡çš„ï¼Œä½ ä¸å¯èƒ½è½»æ˜“åœ°æµ‹é‡å®ƒã€‚æˆ‘æƒ³é‡‡å–ä¸€ç§æ›´å®žé™…çš„æ–¹æ³•ï¼Œå±•ç¤ºå¦‚ä½•åœ¨ä¸€ä¸ªGoé¡¹ç›®ä¸­å¼•å…¥å‡ ç§æµ‹è¯•ã€‚

## Why bother about tests? ä¸ºä»€ä¹ˆè¦ä¸ºæµ‹è¯•è€Œçƒ¦æ¼ï¼Ÿ

But isnâ€™t the test code not as important as the rest of the application? Canâ€™t we just accept that keeping tests in good shape is hard and move on? Wouldnâ€™t it speed up the development?

ä½†æ˜¯ï¼Œæµ‹è¯•ä»£ç ä¸æ˜¯å’Œåº”ç”¨ç¨‹åºçš„å…¶ä»–éƒ¨åˆ†ä¸€æ ·é‡è¦å—ï¼Ÿæˆ‘ä»¬å°±ä¸èƒ½æŽ¥å—ä¿æŒæµ‹è¯•çš„è‰¯å¥½çŠ¶æ€æ˜¯å¾ˆéš¾çš„ï¼Œç„¶åŽç»§ç»­å‰è¿›å—ï¼Ÿè¿™æ ·ä¸æ˜¯å¯ä»¥åŠ å¿«å¼€å‘é€Ÿåº¦å—ï¼Ÿ


If youâ€™ve been following this series, you know we base all posts on the Wild Workouts application.

å¦‚æžœä½ ä¸€ç›´åœ¨å…³æ³¨è¿™ä¸ªç³»åˆ—ï¼Œä½ çŸ¥é“æˆ‘ä»¬æ‰€æœ‰çš„å¸–å­éƒ½æ˜¯åŸºäºŽWild Workoutsåº”ç”¨ç¨‹åºã€‚

When I started writing this article, running tests locally didnâ€™t even work correctly for me, and this is a relatively new project. Thereâ€™s one reason this happened: weâ€™re not running tests in the CI pipeline.

å½“æˆ‘å¼€å§‹å†™è¿™ç¯‡æ–‡ç« æ—¶ï¼Œåœ¨æœ¬åœ°è¿è¡Œæµ‹è¯•å¯¹æˆ‘æ¥è¯´ç”šè‡³ä¸èƒ½æ­£å¸¸å·¥ä½œï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒæ–°çš„é¡¹ç›®ã€‚å‘ç”Ÿè¿™ç§æƒ…å†µæœ‰ä¸€ä¸ªåŽŸå› ï¼šæˆ‘ä»¬æ²¡æœ‰åœ¨`CI pipeline`ä¸­è¿è¡Œæµ‹è¯•ã€‚

Itâ€™s a shock, but it seems even a serverless, cloud-native application using the most popular, cutting edge technologies can be a mess in disguise.

è¿™è®©äººéœ‡æƒŠï¼Œä½†ä¼¼ä¹Žå³ä½¿æ˜¯ä½¿ç”¨æœ€æµè¡Œã€æœ€å‰æ²¿æŠ€æœ¯çš„æ— æœåŠ¡å™¨ã€äº‘åŽŸç”Ÿåº”ç”¨ç¨‹åºä¹Ÿå¯èƒ½æ˜¯å˜ç›¸çš„æ··ä¹±ã€‚

We know we should now add tests to the pipeline. Itâ€™s common knowledge that this gives you the confidence to deploy the changes to production safely. However, thereâ€™s also a cost.

æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬çŽ°åœ¨åº”è¯¥åœ¨ç®¡é“ä¸­åŠ å…¥æµ‹è¯•ã€‚è¿™æ˜¯ä¸€ä¸ªå¸¸è¯†ï¼Œå®ƒä½¿ä½ æœ‰ä¿¡å¿ƒå°†å˜åŒ–å®‰å…¨åœ°éƒ¨ç½²åˆ°ç”Ÿäº§ä¸­ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿæ˜¯æœ‰ä»£ä»·çš„ã€‚

Running tests will likely take a significant part of your pipelineâ€™s duration. If you donâ€™t approach their design and implementation with the same quality as the application code, you can realize it too late, with the pipeline taking one hour to pass and randomly failing on you. Even if your application code is well designed, the tests can become a bottleneck of delivering the changes.

## The Layers åˆ†å±‚

Weâ€™re now after a few refactoring sessions of the project. We introduced patterns like Repository, Clean Architecture, and CQRS. With the solid separation of concerns, we can much easier reason about particular parts of the project.

æˆ‘ä»¬çŽ°åœ¨æ˜¯åœ¨é¡¹ç›®çš„å‡ æ¬¡é‡æž„ä¹‹åŽã€‚æˆ‘ä»¬å¼•å…¥äº†åƒ`Repository`ã€`Clean Architecture`å’Œ`CQRS`ç­‰æ¨¡å¼ã€‚æœ‰äº†åšå®žçš„å…³æ³¨ç‚¹åˆ†ç¦»ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å®¹æ˜“åœ°æŽ¨ç†é¡¹ç›®çš„ç‰¹å®šéƒ¨åˆ†ã€‚


Letâ€™s revisit the concept of layers weâ€™ve introduced in previous posts. If you didnâ€™t have a chance to read these earlier, I recommend doing so before you continue â€” itâ€™ll help you better understand this article.

è®©æˆ‘ä»¬é‡æ¸©ä¸€ä¸‹æˆ‘ä»¬åœ¨ä»¥å‰çš„æ–‡ç« ä¸­ä»‹ç»è¿‡çš„åˆ†å±‚æ¦‚å¿µã€‚å¦‚æžœä½ æ²¡æœ‰æœºä¼šé˜…è¯»è¿™äº›æ–‡ç« ï¼Œæˆ‘å»ºè®®ä½ åœ¨ç»§ç»­ä¹‹å‰é˜…è¯»--å®ƒä¼šå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡æ–‡ç« ã€‚

Take a look at a diagram that will help us understand the projectâ€™s structure. Below is a generic service built with the approach used in Wild Workouts.

è¯·çœ‹ä¸€å¼ å›¾ï¼Œå®ƒå°†å¸®åŠ©æˆ‘ä»¬ç†è§£é¡¹ç›®çš„ç»“æž„ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç”¨`Wild Workouts`ä¸­çš„æ–¹æ³•æž„å»ºçš„é€šç”¨æœåŠ¡ã€‚

å›¾1 https://d33wubrfki0l68.cloudfront.net/4cec6b5f7fe17825645b881925b3f304adde9cc1/67f16/media/microservices-test-architecture/base.jpg

All external inputs start on the left. The only entry point to the application is through the Ports layer (HTTP handlers, Pub/Sub message handlers). Ports execute relevant handlers in the App layer. Some of these will call the Domain code, and some will use Adapters, which are the only way out of the service. The adapters layer is where your database queries and HTTP clients live.

æ‰€æœ‰çš„å¤–éƒ¨è¾“å…¥éƒ½ä»Žå·¦è¾¹å¼€å§‹ã€‚åº”ç”¨ç¨‹åºçš„å”¯ä¸€å…¥å£æ˜¯é€šè¿‡`ports`å±‚ï¼ˆ`HTTP`å¤„ç†ç¨‹åºã€`Pub/Sub`æ¶ˆæ¯å¤„ç†ç¨‹åºï¼‰ã€‚ç«¯å£(Ports)æ‰§è¡Œ`app`å±‚çš„ç›¸å…³å¤„ç†ç¨‹åºã€‚å…¶ä¸­æœ‰äº›ä¼šè°ƒç”¨`domain`å±‚çš„ä»£ç ï¼Œæœ‰äº›ä¼šä½¿ç”¨`adapters`ï¼Œ`adapters`å±‚è¿™æ˜¯ç¦»å¼€æœåŠ¡çš„å”¯ä¸€é€”å¾„ã€‚`adapters`å±‚æ˜¯ä½ çš„æ•°æ®åº“æŸ¥è¯¢å’Œ`HTTP`å®¢æˆ·ç«¯çš„åœ°æ–¹ã€‚

The diagram below shows the layers and flow of a part of the trainer service in Wild Workouts.

ä¸‹å›¾æ˜¾ç¤ºäº†`Wild Workouts`ä¸­åŸ¹è®­å¸ˆæœåŠ¡çš„ä¸€ä¸ªéƒ¨åˆ†çš„å±‚æ¬¡å’Œæµç¨‹ã€‚


å›¾2 https://d33wubrfki0l68.cloudfront.net/190e297aa85a1f492dbda40b29a0b77bdf562ee7/f0c44/media/microservices-test-architecture/example.jpg

Letâ€™s now see what types of tests we would need to cover all of it.

çŽ°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬éœ€è¦å“ªäº›ç±»åž‹çš„æµ‹è¯•æ¥è¦†ç›–æ‰€æœ‰çš„å†…å®¹ã€‚

## Unit tests
We kick off with the inner layers and something everyone is familiar with: unit tests.

æˆ‘ä»¬ä»Žå†…å±‚å’Œå¤§å®¶éƒ½ç†Ÿæ‚‰çš„ä¸œè¥¿å¼€å§‹ï¼šå•å…ƒæµ‹è¯•ã€‚


å›¾3  https://d33wubrfki0l68.cloudfront.net/b2a98a3e50e8b61dea552f706b56a67ecfa61fdd/a340e/media/microservices-test-architecture/unit-tests.jpg


The domain layer is where the most complex logic of your service lives. However, the tests here should be some of the simplest to write and running super fast. There are no external dependencies in the domain, so you donâ€™t need any special infrastructure or mocks (except for really complex scenarios, but letâ€™s leave that for now).

åŸŸå±‚æ˜¯ä½ çš„æœåŠ¡ä¸­æœ€å¤æ‚çš„é€»è¾‘æ‰€åœ¨ã€‚ç„¶è€Œï¼Œè¿™é‡Œçš„æµ‹è¯•åº”è¯¥æ˜¯ä¸€äº›æœ€ç®€å•çš„ç¼–å†™ï¼Œå¹¶ä¸”è¿è¡Œé€Ÿåº¦è¶…å¿«ã€‚åŸŸä¸­æ²¡æœ‰å¤–éƒ¨ä¾èµ–ï¼Œæ‰€ä»¥ä½ ä¸éœ€è¦ä»»ä½•ç‰¹æ®Šçš„åŸºç¡€è®¾æ–½æˆ–æ¨¡æ‹Ÿï¼ˆé™¤äº†éžå¸¸å¤æ‚çš„åœºæ™¯ï¼Œä½†æˆ‘ä»¬çŽ°åœ¨å…ˆä¸è°ˆè¿™ä¸ªï¼‰ã€‚


As a rule of thumb, you should aim for high test coverage in the domain layer. Make sure you test only the exported code (black-box testing). Adding the `_test` suffix to the package name is a great practice to enforce this.

ä½œä¸ºä¸€ä¸ªç»éªŒæ³•åˆ™ï¼Œä½ åº”è¯¥åœ¨`domain`é¢†åŸŸå±‚äº‰å–é«˜çš„æµ‹è¯•è¦†ç›–çŽ‡ã€‚ç¡®ä¿ä½ åªæµ‹è¯•å¯¼å‡ºçš„ä»£ç ï¼ˆé»‘ç›’æµ‹è¯•ï¼‰ã€‚åœ¨åŒ…çš„åç§°ä¸­æ·»åŠ `_test`çš„åŽç¼€æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•æ¥æ‰§è¡Œè¿™ä¸€ç‚¹ã€‚

The domain code is pure logic and straightforward to test, so itâ€™s the best place to check all corner cases. Table-driven tests are especially great for this.

é¢†åŸŸçš„ä»£ç æ˜¯çº¯é€»è¾‘çš„ï¼Œç›´æŽ¥æµ‹è¯•ï¼Œæ‰€ä»¥å®ƒæ˜¯æ£€æŸ¥æ‰€æœ‰è§’è½æƒ…å†µçš„æœ€å¥½åœ°æ–¹ã€‚`è¡¨é©±åŠ¨`(`Table-driven`)çš„æµ‹è¯•åœ¨è¿™æ–¹é¢ç‰¹åˆ«å¥½ã€‚

```go
func TestFactoryConfig_Validate(t *testing.T) {
	testCases := []struct {
		Name        string
		Config      hour.FactoryConfig
		ExpectedErr string
	}{
		{
			Name: "valid",
			Config: hour.FactoryConfig{
				MaxWeeksInTheFutureToSet: 10,
				MinUtcHour:               10,
				MaxUtcHour:               12,
			},
			ExpectedErr: "",
		},
		{
			Name: "equal_min_and_max_hour",
			Config: hour.FactoryConfig{
				MaxWeeksInTheFutureToSet: 10,
				MinUtcHour:               12,
				MaxUtcHour:               12,
			},
			ExpectedErr: "",
		},

		// ...
}

for _, c := range testCases {
		t.Run(c.Name, func(t *testing.T) {
			err := c.Config.Validate()

			if c.ExpectedErr != "" {
				assert.EqualError(t, err, c.ExpectedErr)
			} else {
				assert.NoError(t, err)
			}
}
```
> Full source: [github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainer/domain/hour/hour_test.go](https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/blob/6954ccbd8099648fa12120632102e792ff2377ad/internal/trainer/domain/hour/hour_test.go#L137)

We leave the domain and enter the application layer. After introducing CQRS, weâ€™ve split it further into Commands and Queries.

æˆ‘ä»¬ç¦»å¼€é¢†åŸŸï¼Œè¿›å…¥åº”ç”¨å±‚(`app`)ã€‚åœ¨ä»‹ç»äº†`CQRS`ä¹‹åŽï¼Œæˆ‘ä»¬æŠŠå®ƒè¿›ä¸€æ­¥åˆ†æˆå‘½ä»¤(`Commands`)å’ŒæŸ¥è¯¢(`Queries`)ã€‚

Depending on your project, there could be nothing to test or some complex scenarios to cover. Most of the time, especially in queries, this code just glues together other layers. Testing this doesnâ€™t add any value. But if thereâ€™s any complex orchestration in commands, itâ€™s another good case for unit tests.

æ ¹æ®ä½ çš„é¡¹ç›®ï¼Œå¯èƒ½æ²¡æœ‰ä»€ä¹ˆéœ€è¦æµ‹è¯•çš„ï¼Œä¹Ÿå¯èƒ½æœ‰ä¸€äº›å¤æ‚çš„åœºæ™¯éœ€è¦è¦†ç›–ã€‚å¤§å¤šæ•°æ—¶å€™ï¼Œç‰¹åˆ«æ˜¯åœ¨æŸ¥è¯¢ä¸­ï¼Œè¿™äº›ä»£ç åªæ˜¯æŠŠå…¶ä»–å±‚ç²˜åœ¨ä¸€èµ·ã€‚æµ‹è¯•è¿™ä¸ªå¹¶ä¸å¢žåŠ ä»»ä½•ä»·å€¼ã€‚ä½†æ˜¯ï¼Œå¦‚æžœåœ¨å‘½ä»¤ä¸­å­˜åœ¨ä»»ä½•å¤æ‚çš„åè°ƒï¼Œè¿™å°±æ˜¯å•å…ƒæµ‹è¯•çš„å¦ä¸€ä¸ªå¥½ä¾‹å­ã€‚

> Watch out for complex logic living in the application layer. If you start testing business scenarios here, itâ€™s worth considering introducing the domain layer.

> æ³¨æ„ä½åœ¨åº”ç”¨å±‚çš„å¤æ‚é€»è¾‘ã€‚å¦‚æžœä½ åœ¨è¿™é‡Œå¼€å§‹æµ‹è¯•ä¸šåŠ¡åœºæ™¯ï¼Œå€¼å¾—è€ƒè™‘å¼•å…¥é¢†åŸŸå±‚ã€‚

> On the other hand, itâ€™s the perfect place for orchestration â€” calling adapters and services in a particular order and passing the return values around. If you separate it like that, application tests should not break every time you change the domain code.

> å¦ä¸€æ–¹é¢ï¼Œå®ƒæ˜¯åè°ƒçš„å®Œç¾Žåœºæ‰€--ä»¥ç‰¹å®šçš„é¡ºåºè°ƒç”¨é€‚é…å™¨(`adapters`)å’ŒæœåŠ¡ï¼Œå¹¶ä¼ é€’è¿”å›žå€¼ã€‚å¦‚æžœä½ è¿™æ ·åˆ†å¼€ï¼Œåº”ç”¨æµ‹è¯•å°±ä¸åº”è¯¥åœ¨æ¯æ¬¡æ”¹å˜`domain`å±‚ä»£ç æ—¶ä¸­æ–­ã€‚

**There are many external dependencies in the applicationâ€™s commands and queries**, as opposed to the domain code. They will be trivial to mock if you follow Clean Architecture and use the Dependency Inversion Principle (your code depends on interfaces, not on structs). In most cases, a struct with a single method will make a perfect mock here.

**åœ¨åº”ç”¨ç¨‹åºçš„å‘½ä»¤å’ŒæŸ¥è¯¢ä¸­å­˜åœ¨è®¸å¤šå¤–éƒ¨ä¾èµ–**ï¼Œè€Œä¸æ˜¯é¢†åŸŸ(`domainå±‚)ä»£ç ã€‚å¦‚æžœä½ éµå¾ªæ¸…æ´æž¶æž„å¹¶ä½¿ç”¨ä¾èµ–åè½¬åŽŸåˆ™ï¼ˆä½ çš„ä»£ç ä¾èµ–æŽ¥å£ï¼Œè€Œä¸æ˜¯ä¾èµ–ç»“æž„ï¼‰ï¼Œé‚£ä¹ˆå¯¹å®ƒä»¬è¿›è¡Œæ¨¡æ‹Ÿæ˜¯éžå¸¸ç®€å•çš„ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä¸€ä¸ªåªæœ‰ä¸€ä¸ªæ–¹æ³•çš„ç»“æž„å°±å¯ä»¥æˆä¸ºä¸€ä¸ªå®Œç¾Žçš„æ¨¡æ‹Ÿå¯¹è±¡ã€‚

> If you prefer to use mocking libraries or code-generated mocks, you can use them as well. Go lets you define and implement small interfaces, so we choose to define the mocks ourselves, as itâ€™s the simplest way.

> å¦‚æžœä½ å–œæ¬¢ä½¿ç”¨`mocking`åº“æˆ–ä»£ç ç”Ÿæˆçš„`mock`ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨å®ƒä»¬ã€‚Goå…è®¸ä½ å®šä¹‰å’Œå®žçŽ°å°çš„æŽ¥å£ï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰æ‹©è‡ªå·±å®šä¹‰æ¨¡æ‹Ÿï¼Œå› ä¸ºè¿™æ˜¯æœ€ç®€å•çš„æ–¹æ³•ã€‚

The snippet below shows how an application command is created with injected mocks.

ä¸‹é¢çš„ç‰‡æ®µæ˜¾ç¤ºäº†å¦‚ä½•ç”¨æ³¨å…¥çš„`mock`åˆ›å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºå‘½ä»¤ã€‚

```go
func newDependencies() dependencies {
	repository := &repositoryMock{}
	trainerService := &trainerServiceMock{}
	userService := &userServiceMock{}

	return dependencies{
		repository:     repository,
		trainerService: trainerService,
		userService:    userService,
		handler:        command.NewCancelTrainingHandler(repository, userService, trainerService),
	}
}

// ...

	deps := newDependencies()

	tr := tc.TrainingConstructor()
	deps.repository.Trainings = map[string]training.Training{
		trainingUUID: *tr,
	}

	err := deps.handler.Handle(context.Background(), command.CancelTraining{
		TrainingUUID: trainingUUID,
		User:         training.MustNewUser(requestingUserID, tc.UserType),
	})
```
> Full source: [github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainings/app/command/cancel_training_test.go](https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/blob/22c0a25b67c4669d612a2fa4a434ffae8e35e65a/internal/trainings/app/command/cancel_training_test.go#L73)

Watch out for adding tests that donâ€™t check anything relevant, so you donâ€™t end up testing the mocks. Focus on the logic, and if thereâ€™s none, skip the test altogether.

æ³¨æ„æ·»åŠ äº†é‚£äº›**ä¸æ£€æŸ¥ä»»ä½•ç›¸å…³å†…å®¹çš„æµ‹è¯•**ï¼Œè¿™æ ·ä½ æœ€ç»ˆå°±ä¸ä¼šæ˜¯åªåšäº†mockï¼Œè€Œæ˜¯åšäº†çœŸå®žçš„ä¸šåŠ¡é€»è¾‘ã€‚ã€‚ä¸“æ³¨äºŽé€»è¾‘ï¼Œå¦‚æžœæ²¡æœ‰ï¼Œå°±å®Œå…¨è·³è¿‡æµ‹è¯•ã€‚

Weâ€™ve covered the two inner layers. I guess this didnâ€™t seem novel so far, as weâ€™re all familiar with unit tests. However, **the Continuous Delivery Maturity Model** lists them only on the â€œbaseâ€ maturity level. Letâ€™s now look into integration testing.

æˆ‘ä»¬å·²ç»è¦†ç›–äº†ä¸¤ä¸ªå†…éƒ¨å±‚ã€‚æˆ‘æƒ³åˆ°ç›®å‰ä¸ºæ­¢è¿™ä¼¼ä¹Žå¹¶ä¸æ–°é¢–ï¼Œå› ä¸ºæˆ‘ä»¬éƒ½ç†Ÿæ‚‰å•å…ƒæµ‹è¯•ã€‚ç„¶è€Œï¼Œ[**æŒç»­äº¤ä»˜æˆç†Ÿåº¦**](https://www.infoq.com/articles/Continuous-Delivery-Maturity-Model/)æ¨¡åž‹åªåœ¨ "åŸºç¡€ "æˆç†Ÿåº¦çº§åˆ«ä¸Šåˆ—å‡ºäº†å®ƒä»¬ã€‚çŽ°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹é›†æˆæµ‹è¯•ã€‚

## Integration tests é›†æˆæµ‹è¯•
After reading this header, did you just imagine a long-running test that you have to retry several times to pass? And itâ€™s because of that 30-seconds sleep someone added that turns out to be too short when Jenkins is running under load?

çœ‹å®Œè¿™ä¸ªæ ‡é¢˜ï¼Œä½ æ˜¯å¦æƒ³è±¡åˆ°ä¸€ä¸ªé•¿æœŸè¿è¡Œçš„æµ‹è¯•ï¼Œä½ å¿…é¡»é‡è¯•å‡ æ¬¡æ‰èƒ½é€šè¿‡ï¼Ÿè€Œè¿™æ˜¯å› ä¸ºæœ‰äººæ·»åŠ äº†30ç§’çš„ç¡çœ ï¼Œç»“æžœå‘çŽ°å½“Jenkinsåœ¨è´Ÿè½½ä¸‹è¿è¡Œæ—¶ï¼Œç¡çœ æ—¶é—´å¤ªçŸ­äº†ï¼Ÿ

**Thereâ€™s no reason for integration tests to be slow and flaky. And practices like automatic retries and increasing sleep times should be absolutely out of the question.**

**æ²¡æœ‰ç†ç”±è®©é›†æˆæµ‹è¯•å˜å¾—ç¼“æ…¢å’Œä¸ç¨³å®šã€‚åƒè‡ªåŠ¨é‡è¯•å’Œå¢žåŠ ç¡çœ æ—¶é—´è¿™æ ·çš„åšæ³•åº”è¯¥æ˜¯ç»å¯¹ä¸å¯èƒ½çš„ã€‚**

In our context, an integration test is a test that checks if an adapter works correctly with an external infrastructure. Most of the time, this means testing database repositories.

åœ¨æˆ‘ä»¬çš„è¯­å¢ƒä¸­ï¼Œé›†æˆæµ‹è¯•æ˜¯æ£€æŸ¥ä¸€ä¸ªé€‚é…å™¨æ˜¯å¦èƒ½ä¸Žå¤–éƒ¨åŸºç¡€è®¾æ–½æ­£å¸¸å·¥ä½œçš„æµ‹è¯•ã€‚å¤§å¤šæ•°æ—¶å€™ï¼Œè¿™æ„å‘³ç€æµ‹è¯•æ•°æ®åº“å­˜å‚¨åº“ã€‚

These tests are not about checking whether the database works correctly, but whether you use it correctly (the integration part). Itâ€™s also an excellent way to verify if you know how to use the database internals, like handling transactions.

è¿™äº›æµ‹è¯•ä¸æ˜¯æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æ­£ç¡®å·¥ä½œï¼Œè€Œæ˜¯æ£€æŸ¥ä½ æ˜¯å¦æ­£ç¡®ä½¿ç”¨å®ƒï¼ˆé›†æˆéƒ¨åˆ†ï¼‰ã€‚è¿™ä¹Ÿæ˜¯éªŒè¯ä½ æ˜¯å¦çŸ¥é“å¦‚ä½•ä½¿ç”¨æ•°æ®åº“å†…éƒ¨çš„ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•ï¼Œæ¯”å¦‚å¤„ç†äº‹åŠ¡ã€‚

å›¾4 https://d33wubrfki0l68.cloudfront.net/a2ba90b6fc2e3758d515b0855d3f5a2c899c68de/2d9b4/media/microservices-test-architecture/integration-tests.jpg

Because we need real infrastructure, integration tests are more challenging than unit tests to write and maintain. Usually, we can use docker-compose to spin up all dependencies.

å› ä¸ºæˆ‘ä»¬éœ€è¦çœŸå®žçš„åŸºç¡€è®¾æ–½ï¼Œé›†æˆæµ‹è¯•æ¯”å•å…ƒæµ‹è¯•çš„ç¼–å†™å’Œç»´æŠ¤æ›´å…·æŒ‘æˆ˜æ€§ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`docker-compose`æ¥å¤„ç†å¥½æ‰€æœ‰çš„ä¾èµ–å…³ç³»ã€‚

> Should we test our application with the Docker version of a database? The Docker image will almost always be slightly different than what we run on production. In some cases, like Firestore, thereâ€™s only an emulator available, not the real database.
>
> æˆ‘ä»¬åº”è¯¥ç”¨Dockerç‰ˆæœ¬çš„æ•°æ®åº“æ¥æµ‹è¯•æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºå—ï¼ŸDockeré•œåƒå‡ ä¹Žæ€»æ˜¯ä¸Žæˆ‘ä»¬åœ¨ç”Ÿäº§ä¸­è¿è¡Œçš„ç•¥æœ‰ä¸åŒã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ¯”å¦‚Firestoreï¼Œåªæœ‰ä¸€ä¸ªä»¿çœŸå™¨ï¼Œè€Œä¸æ˜¯çœŸæ­£çš„æ•°æ®åº“ã€‚
>
> Indeed, Docker doesnâ€™t reflect the exact infrastructure you run on production. However, youâ€™re much more likely to mess up an SQL query in the code than to stumble on issues because of a minor configuration difference.
>
> çš„ç¡®ï¼ŒDockerå¹¶ä¸åæ˜ ä½ åœ¨ç”Ÿäº§ä¸­è¿è¡Œçš„ç¡®åˆ‡çš„åŸºç¡€è®¾æ–½ã€‚ç„¶è€Œï¼Œä½ æ›´æœ‰å¯èƒ½åœ¨ä»£ç ä¸­æžä¹±ä¸€ä¸ªSQLæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯å› ä¸ºä¸€ä¸ªå°çš„é…ç½®å·®å¼‚è€Œå¶ç„¶å‘çŽ°é—®é¢˜ã€‚
>
> A good practice is to pin the image version to the same as running on the production. Using Docker wonâ€™t give you 100% production parity, but it eliminates the â€œworks on my machineâ€ issues and tests your code with proper infrastructure.
>
> ä¸€ä¸ªå¥½çš„åšæ³•æ˜¯å°†é•œåƒçš„ç‰ˆæœ¬ä¸Žåœ¨ç”Ÿäº§ä¸­è¿è¡Œçš„ç‰ˆæœ¬ç›¸åŒã€‚ä½¿ç”¨Dockerä¸ä¼šç»™ä½ å¸¦æ¥100%çš„ç”Ÿäº§ä¸€è‡´æ€§ï¼Œä½†å®ƒæ¶ˆé™¤äº† "åœ¨æˆ‘çš„æœºå™¨ä¸Šè¿è¡Œ "çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡é€‚å½“çš„åŸºç¡€è®¾æ–½æµ‹è¯•ä½ çš„ä»£ç ã€‚

Robert covered integration tests for databases in-depth in 4 practical principles of high-quality database integration tests in Go.

Robertåœ¨ã€Š[4 practical principles of high-quality database integration tests in Go](https://threedots.tech/post/database-integration-testing/#2-testing-enough-scenarios-on-all-levels)ã€‹ä¸­æ·±å…¥ä»‹ç»äº†æ•°æ®åº“çš„é›†æˆæµ‹è¯•ã€‚

## Keeping integration tests stable and fast
When dealing with network calls and databases, the test speed becomes super important. Itâ€™s crucial to run tests in parallel, which can be enabled in Go by calling `t.Parallel()`. **It seems simple to do, but we have to make sure our tests support this behavior.**

åœ¨å¤„ç†ç½‘ç»œè°ƒç”¨å’Œæ•°æ®åº“æ—¶ï¼Œæµ‹è¯•é€Ÿåº¦å˜å¾—è¶…çº§é‡è¦ã€‚åœ¨Goä¸­å¯ä»¥é€šè¿‡è°ƒç”¨`t.Parallel()`æ¥å¯ç”¨å¹¶è¡Œæµ‹è¯•ï¼Œè¿™ä¸€ç‚¹è‡³å…³é‡è¦ã€‚è¿™çœ‹èµ·æ¥å¾ˆç®€å•ï¼Œä½†æˆ‘ä»¬å¿…é¡»ç¡®ä¿æˆ‘ä»¬çš„æµ‹è¯•æ”¯æŒè¿™ç§è¡Œä¸ºã€‚

For example, consider this trivial test scenario:

ä¾‹å¦‚ï¼Œè€ƒè™‘è¿™ä¸ªå¾®ä¸è¶³é“çš„æµ‹è¯•åœºæ™¯ã€‚


1. Check if the trainings collection is empty.  æ£€æŸ¥`trainings`é›†åˆæ˜¯å¦ä¸ºç©ºã€‚

2. Call repository method that adds a training. è°ƒç”¨`repository`æ–¹æ³•ï¼Œå¢žåŠ ä¸€ä¸ª`training`ã€‚

3. Check if thereâ€™s one training in the collection. æ£€æŸ¥é›†åˆä¸­æ˜¯å¦æœ‰ä¸€ä¸ª`training`ã€‚


If another test uses the same collection, you will get random fails because of the race condition. Sometimes, the collection will contain more than one training weâ€™ve just added.

å¦‚æžœå¦ä¸€ä¸ªæµ‹è¯•ä½¿ç”¨ç›¸åŒçš„é›†åˆï¼Œä½ ä¼šå› ä¸ºå¹¶å‘è€ŒèŽ·å¾—éšæœºå¤±è´¥ã€‚æœ‰æ—¶ï¼Œé›†åˆä¼šåŒ…å«ä¸æ­¢ä¸€ä¸ªæˆ‘ä»¬åˆšåˆšæ·»åŠ çš„`training`ã€‚


The simplest way out of this is never to assert things like a list length, but check it for the exact thing weâ€™re testing. For example, we could get all trainings, then iterate over the list to check if the expected ID is present.

æœ€ç®€å•çš„æ–¹æ³•æ˜¯æ°¸è¿œä¸è¦æ–­è¨€åƒåˆ—è¡¨é•¿åº¦è¿™æ ·çš„äº‹æƒ…ï¼Œè€Œæ˜¯æ£€æŸ¥æˆ‘ä»¬è¦æµ‹è¯•çš„å…·ä½“å†…å®¹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ‰€æœ‰çš„`trainings`ï¼Œç„¶åŽåœ¨åˆ—è¡¨ä¸­è¿­ä»£ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„æœŸçš„IDã€‚

Another approach is to isolate the tests somehow, so they canâ€™t interfere with each other. For example, each test case can work within a unique userâ€™s context (see component tests below).

å¦ä¸€ç§æ–¹æ³•æ˜¯ä»¥æŸç§æ–¹å¼éš”ç¦»æµ‹è¯•ï¼Œè¿™æ ·ä»–ä»¬å°±ä¸ä¼šäº’ç›¸å¹²æ‰°äº†ã€‚ä¾‹å¦‚ï¼Œæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹å¯ä»¥åœ¨ä¸€ä¸ªç‹¬ç‰¹çš„ç”¨æˆ·çŽ¯å¢ƒä¸­å·¥ä½œï¼ˆè§ä¸‹é¢çš„ç»„ä»¶æµ‹è¯•ï¼‰ã€‚


Of course, both patterns are more complex than a simple length assertion. **When you stumble upon this issue for the first time, it may be tempting to give up and decide that â€œour integration tests donâ€™t need to run in parallelâ€. Donâ€™t do this.** You will need to get creative sometimes, but itâ€™s not that much effort in the end. In return, your integration tests will be stable and running as fast as unit tests.

å½“ç„¶ï¼Œè¿™ä¸¤ç§æ¨¡å¼éƒ½æ¯”ç®€å•çš„é•¿åº¦æ–­è¨€æ›´å¤æ‚ã€‚**å½“ä½ ç¬¬ä¸€æ¬¡å¶ç„¶å‘çŽ°è¿™ä¸ªé—®é¢˜æ—¶ï¼Œä½ å¯èƒ½å¾ˆæƒ³æ”¾å¼ƒï¼Œå†³å®š "æˆ‘ä»¬çš„é›†æˆæµ‹è¯•ä¸éœ€è¦å¹¶è¡Œè¿è¡Œ"ã€‚ä¸è¦è¿™æ ·åšã€‚** ä½ æœ‰æ—¶éœ€è¦å‘æŒ¥åˆ›é€ æ€§ï¼Œä½†æœ€ç»ˆå¹¶æ²¡æœ‰é‚£ä¹ˆå¤šåŠªåŠ›ã€‚ä½œä¸ºå›žæŠ¥ï¼Œä½ çš„é›†æˆæµ‹è¯•å°†æ˜¯ç¨³å®šçš„ï¼Œè¿è¡Œé€Ÿåº¦å’Œå•å…ƒæµ‹è¯•ä¸€æ ·å¿«ã€‚

If you find yourself creating a new database before each run, itâ€™s another sign that you could rework tests to not interfere with each other.

å¦‚æžœä½ å‘çŽ°è‡ªå·±åœ¨æ¯æ¬¡è¿è¡Œå‰éƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®åº“ï¼Œè¿™æ˜¯å¦ä¸€ä¸ªè¿¹è±¡ï¼Œè¯´æ˜Žä½ å¯ä»¥é‡åšæµ‹è¯•ï¼Œä½¿å…¶ä¸äº’ç›¸å¹²æ‰°ã€‚



## Warning! A common, hard-to-spot, gotcha when iterating test cases. è­¦å‘Š! è¿­ä»£æµ‹è¯•ç”¨ä¾‹æ—¶ä¸€ä¸ªå¸¸è§çš„ã€éš¾ä»¥å‘çŽ°çš„é—®é¢˜ã€‚

When working with table-driven tests, youâ€™ll often see code like this:

å½“ä½¿ç”¨è¡¨æ ¼é©±åŠ¨çš„æµ‹è¯•æ—¶ï¼Œä½ ä¼šç»å¸¸çœ‹åˆ°è¿™æ ·çš„ä»£ç :
```go
for _, c := range testCases {
        t.Run(c.Name, func(t *testing.T) {
                // ...
        })
}
```

Itâ€™s an idiomatic way to run tests over a slice of test cases. Letâ€™s say you now want to run each test case in parallel. The solution seems trivial:

è¿™æ˜¯ä¸€ç§ä¹ æƒ¯æ€§çš„æ–¹æ³•ï¼Œåœ¨æµ‹è¯•ç”¨ä¾‹çš„ç‰‡æ–­ä¸Šè¿è¡Œæµ‹è¯•ã€‚å‡è®¾ä½ çŽ°åœ¨æƒ³å¹¶è¡Œåœ°è¿è¡Œæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚è¿™ä¸ªè§£å†³æ–¹æ¡ˆä¼¼ä¹Žå¾ˆç®€å•ã€‚

```go
for _, c := range testCases {
        t.Run(c.Name, func(t *testing.T) {
               t.Parallel()
                // ...
        })
}
```

Sadly, this wonâ€™t work as expected.

é—æ†¾çš„æ˜¯ï¼Œè¿™ä¸ä¼šåƒé¢„æœŸçš„é‚£æ ·å·¥ä½œã€‚

The Common Mistakes page on Goâ€™s GitHub wiki lists just two items, and both are actually about the same thing. So it seems thereâ€™s only one mistake you should worry about in Go. ðŸ™‚ However, this one is really hard to spot sometimes.

`Go`çš„GitHubç»´åŸºä¸Šçš„[å¸¸è§é”™è¯¯](https://github.com/golang/go/wiki/CommonMistakes)é¡µé¢åªåˆ—å‡ºäº†ä¸¤é¡¹ï¼Œè€Œè¿™ä¸¤é¡¹å®žé™…ä¸Šéƒ½æ˜¯å…³äºŽåŒä¸€ä»¶äº‹ã€‚å› æ­¤ï¼Œåœ¨Goä¸­ä¼¼ä¹Žåªæœ‰ä¸€ä¸ªé”™è¯¯æ˜¯ä½ åº”è¯¥æ‹…å¿ƒçš„ã€‚ ðŸ™‚ç„¶è€Œï¼Œè¿™ä¸ªé”™è¯¯æœ‰æ—¶çœŸçš„å¾ˆéš¾å‘çŽ°ã€‚


Itâ€™s not obvious initially, but adding the parallel switch makes the parent test function not wait for the subtests spawned by `t.Run`. Because of this, you canâ€™t safely use the `c` loop variable inside the `func` closure.

æœ€åˆå¹¶ä¸æ˜Žæ˜¾ï¼Œä½†åŠ å…¥å¹¶è¡Œå¼€å…³åŽï¼Œçˆ¶æµ‹è¯•å‡½æ•°å°±ä¸ä¼šç­‰å¾…ç”±`t.Run`å‚¬ç”Ÿçš„å­æµ‹è¯•ã€‚å› ä¸ºè¿™ä¸ªåŽŸå› ï¼Œä½ ä¸èƒ½å®‰å…¨åœ°åœ¨`func`é—­åŒ…å†…ä½¿ç”¨`c`å¾ªçŽ¯å˜é‡ã€‚


Running the tests like this will usually cause all subtests to work with the last test case, ignoring all others. **The worst part is the tests will pass, and you will see correct subtest names when running go test with the -v flag.** The only way to notice this issue is to change the code expecting tests to fail and see them pass instead.

åƒè¿™æ ·è¿è¡Œæµ‹è¯•ï¼Œé€šå¸¸ä¼šå¯¼è‡´æ‰€æœ‰å­æµ‹è¯•ä¸Žæœ€åŽä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸€èµ·å·¥ä½œï¼Œè€Œå¿½ç•¥æ‰€æœ‰å…¶ä»–çš„ã€‚æœ€ç³Ÿç³•çš„æ˜¯æµ‹è¯•ä¼šé€šè¿‡ï¼Œå½“ç”¨-væ ‡å¿—è¿è¡Œæµ‹è¯•æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æ­£ç¡®çš„å­æµ‹è¯•åç§°ã€‚æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜çš„å”¯ä¸€æ–¹æ³•æ˜¯æ”¹å˜æœŸæœ›æµ‹è¯•å¤±è´¥çš„ä»£ç ï¼Œçœ‹åˆ°å®ƒä»¬é€šè¿‡ã€‚

As mentioned in the wiki, one way to fix this is to introduce a new scoped variable:

æ­£å¦‚wikiä¸­æåˆ°çš„ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªæ–¹æ³•æ˜¯å¼•å…¥ä¸€ä¸ªæ–°çš„èŒƒå›´å˜é‡ã€‚

```go
for _, c := range testCases {
        c := c
        t.Run(c.Name, func(t *testing.T) {
               t.Parallel()
                // ...
        })
}
```
Itâ€™s just a matter of taste, but we donâ€™t like this approach, as it looks like some magic spell to anyone who doesnâ€™t know what this means. Instead, we choose the more verbose but obvious approach:
```go
for i := range testCases {
        c := testCases[i]
        t.Run(c.Name, func(t *testing.T) {
               t.Parallel()
                // ...
        })
}
```
Even if you know about this behavior, itâ€™s dangerously easy to misuse it. Whatâ€™s worse, it seems that popular linters donâ€™t check this by default

å³ä½¿ä½ çŸ¥é“è¿™ç§è¡Œä¸ºï¼Œä¹Ÿå¾ˆå®¹æ˜“è¯¯ç”¨å®ƒï¼Œè¿™å¾ˆå±é™©ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œä¼¼ä¹Žæµè¡Œçš„`linter`å¹¶æ²¡æœ‰é»˜è®¤æ£€æŸ¥è¿™ä¸€ç‚¹


We made this mistake in the [Watermill](https://github.com/ThreeDotsLabs/watermill) library, which caused some of the tests not to run at all. You can see the fix in [this commit](https://github.com/ThreeDotsLabs/watermill/commit/c72e26a67cb763ab3dd93ecf57a2b298fc81dd19).

æˆ‘ä»¬åœ¨`Watermill`åº“ä¸­çŠ¯äº†è¿™ä¸ªé”™è¯¯ï¼Œè¿™å¯¼è‡´ä¸€äº›æµ‹è¯•æ ¹æœ¬æ— æ³•è¿è¡Œã€‚ä½ å¯ä»¥åœ¨è¿™ä¸ªæäº¤ä¸­çœ‹åˆ°ä¿®æ­£ã€‚

We covered the database repository with tests, but we also have a gRPC client adapter. How should we test this one?

æˆ‘ä»¬ç”¨æµ‹è¯•è¦†ç›–äº†æ•°æ®åº“å­˜å‚¨åº“ï¼Œä½†æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª`gRPC`å®¢æˆ·ç«¯é€‚é…å™¨(`adapter`)ã€‚æˆ‘ä»¬åº”è¯¥å¦‚ä½•æµ‹è¯•è¿™ä¸ªï¼Ÿ

Itâ€™s similar to the application layer in this regard. If your test would duplicate the code it checks, it probably makes no sense to add it. It just becomes additional work when changing the code.

åœ¨è¿™æ–¹é¢ï¼Œå®ƒä¸Žåº”ç”¨å±‚(`app`å±‚)ç±»ä¼¼ã€‚å¦‚æžœä½ çš„æµ‹è¯•ä¼šé‡å¤å®ƒæ‰€æ£€æŸ¥çš„ä»£ç ï¼Œé‚£ä¹ˆæ·»åŠ å®ƒå¯èƒ½å°±æ²¡æœ‰æ„ä¹‰äº†ã€‚å®ƒåªæ˜¯åœ¨æ”¹å˜ä»£ç æ—¶æˆä¸ºé¢å¤–çš„å·¥ä½œã€‚

Letâ€™s consider the users service gRPC adapter:

è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹ç”¨æˆ·æœåŠ¡gRPCé€‚é…å™¨ã€‚

```go
func (s UsersGrpc) UpdateTrainingBalance(ctx context.Context, userID string, amountChange int) error {
	_, err := s.client.UpdateTrainingBalance(ctx, &users.UpdateTrainingBalanceRequest{
		UserId:       userID,
		AmountChange: int64(amountChange),
	})

	return err
}
```
> Full source: [github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainings/adapters/users_grpc.go](https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/blob/22c0a25b67c4669d612a2fa4a434ffae8e35e65a/internal/trainings/adapters/users_grpc.go#L17)

Thereâ€™s nothing interesting to test here. We could inject a mock client and check whether a proper method has been called. But this wonâ€™t verify anything, and each change in the code will require a corresponding change in the test.

è¿™é‡Œæ²¡æœ‰ä»€ä¹ˆå€¼å¾—æµ‹è¯•çš„ä¸œè¥¿ã€‚æˆ‘ä»¬å¯ä»¥æ³¨å…¥ä¸€ä¸ªæ¨¡æ‹Ÿçš„å®¢æˆ·ç«¯ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦æœ‰ä¸€ä¸ªé€‚å½“çš„æ–¹æ³•è¢«è°ƒç”¨ã€‚ä½†è¿™ä¸ä¼šéªŒè¯ä»»ä½•ä¸œè¥¿ï¼Œè€Œä¸”ä»£ç ä¸­çš„æ¯ä¸€ä¸ªå˜åŒ–éƒ½éœ€è¦æµ‹è¯•ä¸­çš„ç›¸åº”å˜åŒ–ã€‚

## Component tests  ç»„ä»¶æµ‹è¯•
So far, weâ€™ve created mostly narrow, specialized tests for isolated parts of the application. Such tests work great for checking corner cases and specific scenarios, **but it doesnâ€™t mean each service works correctly**. Itâ€™s easy enough to forget to call an application handler from a port. Also, unit tests alone wonâ€™t help us make sure the application still works after a major refactoring.

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»ä¸ºåº”ç”¨ç¨‹åºçš„å­¤ç«‹éƒ¨åˆ†åˆ›å»ºäº†å¤§éƒ¨åˆ†ç‹­çª„çš„ã€ä¸“é—¨çš„æµ‹è¯•ã€‚è¿™æ ·çš„æµ‹è¯•å¯¹äºŽæ£€æŸ¥è§’è½é‡Œçš„æƒ…å†µå’Œç‰¹å®šåœºæ™¯éžå¸¸æœ‰ç”¨ï¼Œ**ä½†è¿™å¹¶ä¸æ„å‘³ç€æ¯ä¸ªæœåŠ¡éƒ½èƒ½æ­£ç¡®å·¥ä½œ**ã€‚å¿˜è®°ä»Žä¸€ä¸ªç«¯å£è°ƒç”¨ä¸€ä¸ªåº”ç”¨ç¨‹åºå¤„ç†ç¨‹åºæ˜¯å¾ˆå®¹æ˜“çš„ã€‚å¦å¤–ï¼Œå•å•æ˜¯å•å…ƒæµ‹è¯•ä¹Ÿä¸èƒ½å¸®åŠ©æˆ‘ä»¬ç¡®ä¿åº”ç”¨ç¨‹åºåœ¨é‡å¤§é‡æž„åŽä»èƒ½å·¥ä½œã€‚

Is it now the time to run end-to-end tests across all our services? Not yet.

çŽ°åœ¨æ˜¯åœ¨æˆ‘ä»¬æ‰€æœ‰çš„æœåŠ¡ä¸­è¿è¡Œç«¯åˆ°ç«¯(`end-to-end`)æµ‹è¯•çš„æ—¶å€™äº†å—ï¼Ÿè¿˜ä¸æ˜¯ã€‚

As there is no standard of calling test types, I encourage you to follow Simon Stewartâ€™s advice from his Test Sizes post. Create a table that will make it obvious for everyone on the team what to expect from a particular test. You can then cut all (unproductive) discussions on the topic.

ç”±äºŽæ²¡æœ‰è°ƒç”¨æµ‹è¯•ç±»åž‹çš„æ ‡å‡†ï¼Œæˆ‘é¼“åŠ±ä½ éµå¾ªSimon Stewartåœ¨ä»–çš„[Test Sizes](https://testing.googleblog.com/2010/12/test-sizes.html)æ–‡ç« ä¸­çš„å»ºè®®ã€‚åˆ›å»ºä¸€ä¸ªè¡¨æ ¼ï¼Œè®©å›¢é˜Ÿä¸­çš„æ¯ä¸ªäººéƒ½æ¸…æ¥šåœ°çŸ¥é“å¯¹æŸä¸ªç‰¹å®šæµ‹è¯•çš„æœŸæœ›ã€‚ç„¶åŽï¼Œä½ å¯ä»¥å‰Šå‡æ‰€æœ‰å…³äºŽè¯¥ä¸»é¢˜çš„ï¼ˆæ— ç›Šçš„ï¼‰è®¨è®ºã€‚

In our case, the table could look like this:

åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œè¯¥è¡¨å¯ä»¥æ˜¯è¿™æ ·çš„ã€‚
![](../../img/ddd-test-size.png)

To ensure each service works correctly internally, **we introduce component tests to check all layers working together**. A component test covers a single service, isolated from other services in the application.

ä¸ºäº†ç¡®ä¿æ¯ä¸ªæœåŠ¡åœ¨å†…éƒ¨æ­£å¸¸å·¥ä½œï¼Œ**æˆ‘ä»¬å¼•å…¥äº†ç»„ä»¶æµ‹è¯•æ¥æ£€æŸ¥æ‰€æœ‰å±‚çš„å·¥ä½œæƒ…å†µ**ã€‚ä¸€ä¸ªç»„ä»¶æµ‹è¯•æ¶µç›–ä¸€ä¸ªå•ä¸€çš„æœåŠ¡ï¼Œä¸Žåº”ç”¨ç¨‹åºä¸­çš„å…¶ä»–æœåŠ¡éš”ç¦»ã€‚

We will call real port handlers and use the infrastructure provided by Docker. However, we will **mock all adapters reaching external services**.

æˆ‘ä»¬å°†è°ƒç”¨çœŸæ­£çš„ç«¯å£å¤„ç†ç¨‹åºå¹¶ä½¿ç”¨`Docker`æä¾›çš„åŸºç¡€è®¾æ–½ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å°†**æ¨¡æ‹Ÿæ‰€æœ‰åˆ°è¾¾å¤–éƒ¨æœåŠ¡çš„é€‚é…å™¨**ã€‚

å›¾5 https://d33wubrfki0l68.cloudfront.net/4ed137e99028c95b146a62f7257ac75de76e49f7/5354d/media/microservices-test-architecture/component-tests.jpg

You might be wondering, why not test external services as well? After all, we could use Docker containers and test all of them together.

The issue is the complexity of testing several connected services. If you have just a couple of them, that can work well enough. But remember, you need to have the proper infrastructure in place for each service you spin up, including all databases it uses and all external services it calls. It can easily be tens of services in total, usually owned by multiple teams.

å›¾6 https://d33wubrfki0l68.cloudfront.net/ddb219c1afe9be5f7768bc174c6de056dbdf5c66/2b26e/media/microservices-test-architecture/setting-up-end-to-end.jpg

Weâ€™ll come to this next in end-to-end tests. But for now, we add component tests because we need a fast way to know if a service works correctly.

To better understand why itâ€™s essential to have component tests in place, I suggest looking at some quotes from Accelerate.

> If you havenâ€™t heard about Accelerate yet, itâ€™s a book describing research on high-performing software teams. I recommend reading it to learn what can help your team get up to speed.

According to the book, this is what the best software teams said about testability.

> We can do most of our testing without requiring an integrated environment. We can and do deploy or release our application independently of other applications/services it depends on.  ------[Accelerate](https://itrevolution.com/book/accelerate/)


Wait, werenâ€™t microservices supposed to fix teams being dependent on each other? If you think itâ€™s impossible to achieve this in the application you work on, itâ€™s likely because of poor architecture choices. You can fix it by applying strategic DDD patterns that we plan to introduce in future posts.

Accelerate follows up with:

> Unfortunately, in real life, many so-called service-oriented architectures donâ€™t permit testing and deploying services independently of each other, and thus will not enable teams to achieve higher performance.  ------[Accelerate](https://itrevolution.com/book/accelerate/)

We raise this point through the series: using microservices doesnâ€™t make your application and teams less coupled by itself. Decoupling takes a conscious design of the applicationâ€™s architecture and at the system level.

In component tests, our goal is to check the completeness of a single service in isolation, with all infrastructure it needs. We make sure the service accepts the API we agreed on and responds with expected results.

These tests are more challenging technically, but still relatively straightforward. We wonâ€™t be running a real service binary because we need to mock some dependencies. We have to modify the way we start the service to make it possible.

> Once again, if you follow the Dependency Inversion Principle (just a reminder, itâ€™s part of SOLID), injecting mocks at the service level should be trivial.

Iâ€™ve introduced two constructors for our app.Application struct, which holds all commands and queries. The first one works just like before, setting up real gRPC clients and injecting them. The second replaces them with mocks.

```go
func NewApplication(ctx context.Context) (app.Application, func()) {
	// ...

	trainerGrpc := adapters.NewTrainerGrpc(trainerClient)
	usersGrpc := adapters.NewUsersGrpc(usersClient)

	return newApplication(ctx, trainerGrpc, usersGrpc),
	// ...
}

func NewComponentTestApplication(ctx context.Context) app.Application {
	return newApplication(ctx, TrainerServiceMock{}, UserServiceMock{})
}
```
> Full source: [github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainings/service/service.go](https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/blob/0e3e9d80eb14639bc42935795f7ca3b73da36304/internal/trainings/service/service.go#L35)

We can now simply run the service in a separate goroutine.

We want to run just a single service instance for all tests, so we use the TestMain function. Itâ€™s a simple way to insert a setup before running tests.